{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Qwen2.5-VL + Sensor Training Walkthrough\n",
        "\n",
        "\uc774 \ub178\ud2b8\ubd81\uc740 `model_with_sensor.py` \uae30\ubc18 \ud559\uc2b5 \ud30c\uc774\ud504\ub77c\uc778\uc744 \ud55c \ub2e8\uacc4\uc529 \ud655\uc778\ud558\uae30 \uc704\ud55c \ucc38\uace0\uc6a9 \uc2a4\ud06c\ub9bd\ud2b8\uc785\ub2c8\ub2e4.\n",
        "\uac01 \uc140\uc744 \uc21c\uc11c\ub300\ub85c \uc2e4\ud589\ud558\uba74\uc11c \ub370\uc774\ud130 \ub85c\ub354, \uce90\uc2dc \uc0dd\uc131, \ucd5c\uc885 \ud559\uc2b5 \ub8e8\ud504\uac00 \ubaa8\ub450 \ub3d9\uc791\ud558\ub294\uc9c0 \uc810\uac80\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# \u2705 \ud504\ub85c\uc81d\ud2b8 \uacbd\ub85c \ubc0f \uae30\ubcf8 \ud658\uacbd \uc124\uc815\n",
        "import os\n",
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "PROJECT_ROOT = Path(r\"/workspace/Insertion_VLA\")\n",
        "os.chdir(PROJECT_ROOT)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Project root: {{PROJECT_ROOT}}')\n",
        "print(f'Using device: {{device}}')\n",
        "if device.type == 'cuda':\n",
        "    print(f'CUDA device name: {torch.cuda.get_device_name(device)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. \ud559\uc2b5/\uce90\uc2dc \uad6c\uc131 \ud30c\ub77c\ubbf8\ud130\n",
        "\ud544\uc694\uc5d0 \ub530\ub77c \uacbd\ub85c\uc640 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub97c \uc218\uc815\ud558\uc138\uc694. \ub370\uc774\ud130 \ub8e8\ud2b8\ub294 \uc2e4\uc81c JSON/\uc774\ubbf8\uc9c0 \ud30c\uc77c\uc774 \uc874\uc7ac\ud558\ub294 \uc704\uce58\uc5ec\uc57c \ud569\ub2c8\ub2e4.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "DATA_ROOT = Path('/home/najo/NAS/VLA/dataset')  # \u26a0\ufe0f \ub370\uc774\ud130 \uacbd\ub85c\ub97c \uc2e4\uc81c \uc704\uce58\ub85c \uc218\uc815\ud558\uc138\uc694.\n",
        "CACHE_DIR = Path('/home/najo/NAS/VLA/dataset/cache/qwen_vl_features')\n",
        "VL_MODEL_NAME = 'Qwen/Qwen2.5-VL-3B-Instruct'\n",
        "\n",
        "# \ud559\uc2b5 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\n",
        "BATCH_SIZE = 1\n",
        "VAL_RATIO = 0.05\n",
        "NUM_EPOCHS = 1\n",
        "GRAD_ACCUM_STEPS = 8\n",
        "BASE_LR = 1e-4\n",
        "VL_LR = 1e-5\n",
        "VISION_LR = 5e-6\n",
        "MIN_LR = 1e-6\n",
        "WARMUP_RATIO = 0.03\n",
        "HOLD_RATIO = 0.02\n",
        "SCHED_ON = 'step'  # 'step' \ub610\ub294 'epoch'\n",
        "\n",
        "# VL \ubc31\ubcf8 \ud30c\uc778\ud29c\ub2dd \uc635\uc158\n",
        "FINETUNE_VL = 'lora'  # {'none', 'lora', 'full'}\n",
        "LORA_R = 16\n",
        "LORA_ALPHA = 32\n",
        "LORA_DROPOUT = 0.05\n",
        "UNFREEZE_LAST_N = 2\n",
        "\n",
        "# \uce90\uc2dc \uc124\uc815\n",
        "CACHE_MODE = 'auto'  # {'auto', 'strict', 'off'}\n",
        "CACHE_MAX_GB = 20.0\n",
        "CACHE_WARMUP_SAMPLES = 16  # \uce90\uc2dc \ub9ac\ud5c8\uc124\uc6a9 \uc0d8\ud50c \uc218\n",
        "\n",
        "RUN_ID = datetime.now().strftime('notebook_%m%d_%H%M')\n",
        "CHECKPOINT_PATH = Path('./checkpoints') / f'{RUN_ID}_latest.pt'\n",
        "CHECKPOINT_PATH.parent.mkdir(exist_ok=True, parents=True)\n",
        "print(f'Checkpoints will be saved to: {CHECKPOINT_PATH}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. \ub370\uc774\ud130\uc14b \ub85c\ub529\n",
        "Meca500 / ZED JSON \uacbd\ub85c\ub97c \uc790\ub3d9\uc73c\ub85c \uc218\uc9d1\ud55c \ub4a4 `insertionMeca500Dataset`\uc73c\ub85c \ubd88\ub7ec\uc635\ub2c8\ub2e4.\n",
        "\ub370\uc774\ud130 \uad6c\uc870\uac00 \ub2e4\ub974\ub2e4\uba74 \uc774 \uc140\uc744 \uc218\uc815\ud574 \uc8fc\uc138\uc694.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from Total_Dataset import insertionMeca500Dataset, collate_fn\n",
        "from torch.utils.data import ConcatDataset, random_split, DataLoader, Subset\n",
        "\n",
        "assert DATA_ROOT.exists(), f'Data root not found: {DATA_ROOT}'\n",
        "meca_jsons = sorted(DATA_ROOT.glob('OCT_insertion/Captures*/Captures*_precise_9views.json'))\n",
        "zed_jsons = sorted(DATA_ROOT.glob('part*/ZED_Captures_*th/ZED_Captures_*th_precise_8views.json'))\n",
        "\n",
        "if not meca_jsons:\n",
        "    raise FileNotFoundError('Meca500 JSON \uacbd\ub85c\ub97c \ucc3e\uc744 \uc218 \uc5c6\uc2b5\ub2c8\ub2e4. DATA_ROOT\ub97c \ud655\uc778\ud558\uc138\uc694.')\n",
        "if not zed_jsons:\n",
        "    raise FileNotFoundError('ZED JSON \uacbd\ub85c\ub97c \ucc3e\uc744 \uc218 \uc5c6\uc2b5\ub2c8\ub2e4. DATA_ROOT\ub97c \ud655\uc778\ud558\uc138\uc694.')\n",
        "\n",
        "def build_insertion_dataset(json_paths, horizon=8):\n",
        "    return ConcatDataset([insertionMeca500Dataset(json_path=str(p), horizon=horizon) for p in json_paths])\n",
        "\n",
        "meca_ds = build_insertion_dataset(meca_jsons)\n",
        "zed_ds = build_insertion_dataset(zed_jsons)\n",
        "full_dataset = ConcatDataset([meca_ds, zed_ds])\n",
        "print(f'Total samples: {len(full_dataset)} (Meca: {len(meca_ds)}, ZED: {len(zed_ds)})')\n",
        "\n",
        "val_len = max(1, int(len(full_dataset) * VAL_RATIO)) if len(full_dataset) > 1 else 0\n",
        "train_len = len(full_dataset) - val_len\n",
        "if val_len > 0 and train_len > 0:\n",
        "    train_dataset, val_dataset = random_split(full_dataset, [train_len, val_len])\n",
        "else:\n",
        "    train_dataset, val_dataset = full_dataset, None\n",
        "\n",
        "loader_kwargs = dict(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=4,\n",
        "    collate_fn=collate_fn,\n",
        "    pin_memory=(device.type == 'cuda'),\n",
        ")\n",
        "if loader_kwargs['num_workers'] > 0:\n",
        "    loader_kwargs['persistent_workers'] = True\n",
        "    loader_kwargs['prefetch_factor'] = max(2, BATCH_SIZE)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, shuffle=True, **loader_kwargs)\n",
        "val_loader = None\n",
        "if val_dataset is not None and len(val_dataset) > 0:\n",
        "    val_loader = DataLoader(val_dataset, shuffle=False, **loader_kwargs)\n",
        "\n",
        "example_batch = next(iter(train_loader))\n",
        "print(f\"Loaded example batch -> actions shape: {example_batch['actions'].shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. \ubaa8\ub378 \ucd08\uae30\ud654 \ubc0f \uce90\uc2dc \uc124\uc815\n",
        "`Not_freeze_QwenVLAWithSensor`\ub97c \uadf8\ub300\ub85c \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \ud544\uc694\ud55c \uacbd\uc6b0 \uc13c\uc11c \ubaa8\ub4c8 \ud65c\uc131\ud654\ub098 \ud30c\uc778\ud29c\ub2dd \ubaa8\ub4dc\ub97c \ubcc0\uacbd\ud558\uc138\uc694.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from model_with_sensor import Not_freeze_QwenVLAWithSensor\n",
        "from 5st_VLA_TRAIN_VL_Lora import unwrap_model\n",
        "\n",
        "model = Not_freeze_QwenVLAWithSensor(\n",
        "    vl_model_name=VL_MODEL_NAME,\n",
        "    action_dim=7,\n",
        "    horizon=8,\n",
        "    hidden_dim=1024,\n",
        "    finetune_vl=FINETUNE_VL,\n",
        "    lora_r=LORA_R,\n",
        "    lora_alpha=LORA_ALPHA,\n",
        "    lora_dropout=LORA_DROPOUT,\n",
        "    unfreeze_last_n=UNFREEZE_LAST_N,\n",
        "    sensor_enabled=False,\n",
        "    fusion_strategy='none',\n",
        "    cache_dir=str(CACHE_DIR),\n",
        ").to(device)\n",
        "\n",
        "module_ref = unwrap_model(model)\n",
        "module_ref.set_cache_limit(CACHE_MAX_GB)\n",
        "if CACHE_MODE == 'strict':\n",
        "    module_ref.set_cache(True)\n",
        "    module_ref.set_strict_cache(True)\n",
        "elif CACHE_MODE == 'off':\n",
        "    module_ref.set_cache(False)\n",
        "    module_ref.set_strict_cache(False)\n",
        "else:\n",
        "    module_ref.set_cache(True)\n",
        "    module_ref.set_strict_cache(False)\n",
        "\n",
        "trainable_params = sum(p.numel() for p in module_ref.parameters() if p.requires_grad)\n",
        "total_params = sum(p.numel() for p in module_ref.parameters())\n",
        "print(f'Trainable params: {trainable_params/1e6:.2f}M / Total: {total_params/1e6:.2f}M')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. (\uc120\ud0dd) VL \uce90\uc2dc \ub9ac\ud5c8\uc124\n",
        "\ub300\uaddc\ubaa8 \ud559\uc2b5 \uc804\uc5d0 \uc18c\uc218\uc758 \uc0d8\ud50c\ub85c \uce90\uc2dc \uc0dd\uc131\uc774 \uc815\uc0c1 \ub3d9\uc791\ud558\ub294\uc9c0 \ud655\uc778\ud569\ub2c8\ub2e4.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from Make_VL_cache import build_vl_cache_distributed_optimized\n",
        "\n",
        "if CACHE_MODE != 'off':\n",
        "    warmup_count = min(CACHE_WARMUP_SAMPLES, len(train_dataset))\n",
        "    cache_subset = train_dataset if warmup_count == len(train_dataset) else Subset(train_dataset, range(warmup_count))\n",
        "    print(f'Building cache for {len(cache_subset)} samples...')\n",
        "    build_vl_cache_distributed_optimized(\n",
        "        model=module_ref,\n",
        "        dataset=cache_subset,\n",
        "        device=device,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        max_cache_gb=CACHE_MAX_GB,\n",
        "    )\n",
        "else:\n",
        "    print('Cache mode is OFF \u2014 skipping cache warmup.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. \uc635\ud2f0\ub9c8\uc774\uc800 & \uc2a4\ucf00\uc904\ub7ec \uad6c\uc131\n",
        "\ud559\uc2b5 \uc2a4\ud06c\ub9bd\ud2b8\uc640 \ub3d9\uc77c\ud55c weight decay \ubd84\ud560 \ub85c\uc9c1\uc744 \uc7ac\uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import math\n",
        "from torch.optim import AdamW\n",
        "from 5st_VLA_TRAIN_VL_Lora import build_trapezoid_scheduler\n",
        "\n",
        "def wd_filter(name, param):\n",
        "    if param.ndim == 1:\n",
        "        return False\n",
        "    if name.endswith('.bias'):\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "ae_named = list(module_ref.action_expert.named_parameters())\n",
        "vl_named = list(module_ref.vl_model.named_parameters())\n",
        "\n",
        "ae_decay = [p for n, p in ae_named if wd_filter(n, p) and p.requires_grad]\n",
        "ae_n_decay = [p for n, p in ae_named if not wd_filter(n, p) and p.requires_grad]\n",
        "vl_decay = [p for n, p in vl_named if wd_filter(n, p) and p.requires_grad]\n",
        "vl_n_decay = [p for n, p in vl_named if not wd_filter(n, p) and p.requires_grad]\n",
        "vision_decay, vision_n_decay = [], []\n",
        "for n, p in vl_named:\n",
        "    if not p.requires_grad:\n",
        "        continue\n",
        "    if any(key in n for key in ('vision', 'visual', 'vision_tower')):\n",
        "        (vision_decay if wd_filter(n, p) else vision_n_decay).append(p)\n",
        "\n",
        "param_groups = [\n",
        "    {'params': ae_decay, 'lr': BASE_LR, 'weight_decay': 0.01},\n",
        "    {'params': ae_n_decay, 'lr': BASE_LR, 'weight_decay': 0.0},\n",
        "]\n",
        "if FINETUNE_VL == 'lora':\n",
        "    param_groups += [\n",
        "        {'params': vl_decay, 'lr': VL_LR, 'weight_decay': 0.01},\n",
        "        {'params': vl_n_decay, 'lr': VL_LR, 'weight_decay': 0.0},\n",
        "    ]\n",
        "elif FINETUNE_VL == 'full':\n",
        "    param_groups += [\n",
        "        {'params': vision_decay, 'lr': VISION_LR, 'weight_decay': 0.01},\n",
        "        {'params': vision_n_decay, 'lr': VISION_LR, 'weight_decay': 0.0},\n",
        "        {'params': vl_decay, 'lr': VL_LR, 'weight_decay': 0.01},\n",
        "        {'params': vl_n_decay, 'lr': VL_LR, 'weight_decay': 0.0},\n",
        "    ]\n",
        "\n",
        "optimizer = AdamW(param_groups, betas=(0.9, 0.999), eps=1e-8)\n",
        "\n",
        "steps_per_epoch = math.ceil(len(train_loader) / max(1, GRAD_ACCUM_STEPS))\n",
        "total_steps = max(1, steps_per_epoch * NUM_EPOCHS)\n",
        "scheduler = build_trapezoid_scheduler(\n",
        "    optimizer,\n",
        "    total_steps=total_steps,\n",
        "    base_lr=BASE_LR,\n",
        "    min_lr=MIN_LR,\n",
        "    warmup_ratio=WARMUP_RATIO,\n",
        "    hold_ratio=HOLD_RATIO,\n",
        ")\n",
        "print(f'Scheduler total steps: {total_steps}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. \ud559\uc2b5 \ub8e8\ud504 \uc2e4\ud589\n",
        "`Train` \ud568\uc218\ub97c \uadf8\ub300\ub85c \ud638\ucd9c\ud558\ub418 W&B \ub85c\uae45\uc740 \ube44\ud65c\uc131\ud654\ud558\uc5ec \ub178\ud2b8\ubd81 \uc2e4\ud5d8\uc5d0 \uc9d1\uc911\ud569\ub2c8\ub2e4.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from 5st_VLA_TRAIN_VL_Lora import Train\n",
        "\n",
        "Train(\n",
        "    model=model,\n",
        "    data_loader=train_loader,\n",
        "    optimizer=optimizer,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    grad_accum_steps=GRAD_ACCUM_STEPS,\n",
        "    device=device,\n",
        "    save_path=str(CHECKPOINT_PATH),\n",
        "    scheduler=scheduler,\n",
        "    sched_on=SCHED_ON,\n",
        "    val_loader=val_loader,\n",
        "    start_epoch=0,\n",
        "    enable_wandb=False,\n",
        ")\n",
        "print('Training run finished.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. \ucd94\ub860/\uac80\uc99d \uc0d8\ud50c \ud655\uc778\n",
        "\ud559\uc2b5 \ud6c4 \ubaa8\ub378\uc774 \ubc30\uce58 \ud558\ub098\ub97c \ucc98\ub9ac\ud558\ub294\uc9c0 \uac04\ub2e8\ud788 \uc810\uac80\ud569\ub2c8\ub2e4.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    sample = next(iter(train_loader))\n",
        "    actions = sample['actions'].to(device, dtype=torch.bfloat16)\n",
        "    preds, _ = model(\n",
        "        text_inputs=sample['instruction'],\n",
        "        image_inputs=sample['images'],\n",
        "        z_chunk=actions,\n",
        "        sensor_data=sample.get('sensor_data'),\n",
        "        cache_keys=sample['cache_keys'],\n",
        "    )\n",
        "print(f'Predicted actions shape: {preds.shape}')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}