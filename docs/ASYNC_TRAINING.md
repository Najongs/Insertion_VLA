# Asynchronous VLA Training and Inference

## ê°œìš”

ê¸°ì¡´ VLA ëª¨ë¸ì€ VLMê³¼ Action Expertê°€ ë™ê¸°ì ìœ¼ë¡œ ë™ì‘í•˜ì—¬ ì¶”ë¡  ì†ë„ê°€ ëŠë ¸ìŠµë‹ˆë‹¤. ì´ ë¬¸ì„œëŠ” ë¹„ë™ê¸° í•™ìŠµ ë° ì¶”ë¡ ì„ í†µí•´ **VLMì„ ~3.33 Hzë¡œ, Action Expertë¥¼ 10 Hzë¡œ ë™ì‘**ì‹œì¼œ ì‹¤ì‹œê°„ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

---

## ë¬¸ì œì : ê¸°ì¡´ ë™ê¸°ì‹ êµ¬ì¡°

### ê¸°ì¡´ ëª¨ë¸ êµ¬ì¡°
```
VLM (Qwen2.5-VL) â†’ VL Features (ë§¤ ì¶”ë¡ ë§ˆë‹¤ ì‹¤í–‰, ~311ms)
    â†“
Sensor Encoder (650 timesteps)
    â†“
Action Expert
    â†“
8 Actions (Horizon=8)
```

**ë¬¸ì œ:**
- VLM ì¶”ë¡  ì‹œê°„: ~311ms (3.21 Hz)
- ì „ì²´ íŒŒì´í”„ë¼ì¸ì´ VLM ì†ë„ì— ì¢…ì†
- 1ì´ˆì— ìµœëŒ€ ~3ë²ˆë§Œ action ìƒì„± ê°€ëŠ¥
- ì‹¤ì‹œê°„ ì œì–´ì— ë¶€ì í•©

---

## í•´ê²°ì±…: ë¹„ë™ê¸° êµ¬ì¡°

### âš ï¸ ì¤‘ìš”: í•™ìŠµ vs ì¶”ë¡ 

**í•™ìŠµ ì‹œ (Training):**
- VL ìºì‹œë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹ ë¥´ê²Œ VL features ì¶”ì¶œ (~ìˆ˜ ms)
- VL featuresë¥¼ 3ë²ˆ ì¬ì‚¬ìš©í•˜ë©° í•™ìŠµ
- ì‹¤ì œ VLM ì‹¤í–‰ ì•ˆ í•¨ (ìºì‹œëœ features ì‚¬ìš©)

**ì¶”ë¡  ì‹œ (Inference):**
- VL ìºì‹œë¥¼ **ì‚¬ìš©í•˜ì§€ ì•ŠìŒ** (`cache_mode="off"`)
- ì‹¤ì œ VLMì„ ì‹¤í–‰í•˜ì—¬ VL features ì¶”ì¶œ (~311ms)
- VLMì„ **ë³„ë„ ìŠ¤ë ˆë“œ**ì—ì„œ ë°±ê·¸ë¼ìš´ë“œë¡œ ì‹¤í–‰
- Action ExpertëŠ” ë©”ì¸ ë£¨í”„ì—ì„œ 10 Hzë¡œ ê³„ì† ë™ì‘

### VLM ì¶”ë¡  ì†ë„ í”„ë¡œíŒŒì¼ë§

ë¨¼ì € ì‹¤ì œ VLM ì¶”ë¡  ì†ë„ë¥¼ ì¸¡ì •:

```bash
python utils/profile_vlm_speed.py --num-samples 50 --save-results vlm_profile_results.json
```

**ì¸¡ì • ê²°ê³¼ (ë‹¨ì¼ ì´ë¯¸ì§€):**
- VLM í‰ê·  ì¶”ë¡  ì‹œê°„: **311 ms**
- VLM ì²˜ë¦¬ëŸ‰: **3.21 Hz**

**âš ï¸ ì‹¤ì œ ë©€í‹°ë·° 5ê°œ ì‚¬ìš© ì‹œ:**
- VLM í‰ê·  ì¶”ë¡  ì‹œê°„: **1484 ms**
- VLM ì²˜ë¦¬ëŸ‰: **0.67 Hz**
- **ê¶Œì¥ ì„¤ì •: VLM 0.59 Hz (1700ms ì£¼ê¸°), VL featuresë¥¼ 17ë²ˆ ì¬ì‚¬ìš©**

### ë¹„ë™ê¸° ì•„í‚¤í…ì²˜ (ë©€í‹°ë·° 5ê°œ ê¸°ì¤€)

```
ğŸ• ì‹œê°„ ì¶• (ì˜ˆì‹œ):
â”œâ”€ VLM Inference (0.59Hz = 1700msë§ˆë‹¤, ë©€í‹°ë·° 5ê°œ)
â”‚  â”œâ”€ t=0ms      â†’ VL_feat_0 (1484ms ì†Œìš”, ë°±ê·¸ë¼ìš´ë“œ)
â”‚  â”œâ”€ t=1700ms   â†’ VL_feat_1 (1484ms ì†Œìš”, ë°±ê·¸ë¼ìš´ë“œ)
â”‚  â”œâ”€ t=3400ms   â†’ VL_feat_2
â”‚  â””â”€ ...
â”‚
â””â”€ Action Expert (10Hz = 100msë§ˆë‹¤)
   â”œâ”€ t=0ms:     [VL_feat_0 + sensor[0:65]]      â†’ 8 actions
   â”œâ”€ t=100ms:   [VL_feat_0 + sensor[65:130]]    â†’ 8 actions (ì¬ì‚¬ìš© #1)
   â”œâ”€ t=200ms:   [VL_feat_0 + sensor[130:195]]   â†’ 8 actions (ì¬ì‚¬ìš© #2)
   â”œâ”€ ...
   â”œâ”€ t=1600ms:  [VL_feat_0 + sensor[1040:1105]] â†’ 8 actions (ì¬ì‚¬ìš© #16)
   â”œâ”€ t=1700ms:  [VL_feat_1 + sensor[1105:1170]] â†’ 8 actions (ìƒˆ VL_feat)
   â””â”€ ...

ì´ ì¶œë ¥: 10íšŒ Ã— 8 actions = 80 actions/sec âœ…
```

**í•µì‹¬ ë³€ê²½ì‚¬í•­:**
1. **VLM ì£¼ê¸°**: 1700msë§ˆë‹¤ ì‹¤í–‰ (~0.59 Hz) - ë©€í‹°ë·° 5ê°œ ì²˜ë¦¬
2. **VLM ì‹¤ì œ ì‹¤í–‰ ì‹œê°„**: 1484ms (ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ)
3. **Sensor window**: 650 â†’ 65 timesteps (100ms @ 650Hz)
4. **Action Expert ì£¼ê¸°**: 100msë§ˆë‹¤ ì‹¤í–‰ (10 Hz)
5. **VL feature ì¬ì‚¬ìš©**: ê°™ì€ VL featureë¥¼ **17ë²ˆ** ì¬ì‚¬ìš©

---

## êµ¬í˜„

### 1. ë¹„ë™ê¸° ëª¨ë¸ í´ë˜ìŠ¤

`models/model_with_sensor_async.py`:

```python
from models.model_with_sensor_async import AsyncQwenVLAWithSensor, create_async_model

# ëª¨ë¸ ìƒì„±
model = create_async_model(
    finetune_vl="lora",
    sensor_window_size=65,      # 100ms @ 650Hz
    vlm_reuse_count=3,          # VL feature 3ë²ˆ ì¬ì‚¬ìš©
    stage1_checkpoint="path/to/stage1.pt",
)
```

**ì£¼ìš” ë©”ì„œë“œ:**
- `extract_vl_features()`: VL featuresë§Œ ì¶”ì¶œ (ìºì‹±ìš©)
- `predict_actions_with_cached_vl()`: ìºì‹œëœ VL featuresë¡œ action ì˜ˆì¸¡
- `forward()`: ì¼ë°˜ forward ë˜ëŠ” ìºì‹œëœ VL features ì‚¬ìš© ê°€ëŠ¥

### 2. ë¹„ë™ê¸° í•™ìŠµ

`training/A6_VLA_TRAIN_ASYNC.py`:

```bash
# ë©€í‹° GPU í•™ìŠµ
torchrun --nproc_per_node=4 training/A6_VLA_TRAIN_ASYNC.py \
    --finetune-vl lora \
    --sensor-window-size 65 \
    --vlm-reuse-count 3 \
    --sensor-enabled \
    --batch-size 2 \
    --lr 1e-4 \
    --sensor-lr 5e-4 \
    --vl-lr 1e-5
```

**í•™ìŠµ ì „ëµ:**
- VL featuresë¥¼ í•œ ë²ˆ ì¶”ì¶œí•˜ê³  `vlm_reuse_count`ë²ˆ ì¬ì‚¬ìš©
- ê° ì¬ì‚¬ìš© ì‹œ ë‹¤ë¥¸ sensor window ì‚¬ìš©
- ëª¨ë¸ì´ "ì•½ê°„ ì˜¤ë˜ëœ VL features"ë¡œë„ ë™ì‘í•˜ë„ë¡ í•™ìŠµ

### 3. ë¹„ë™ê¸° ì¶”ë¡  (ì‹¤ì‹œê°„)

`examples/async_inference_example.py`:

```bash
python examples/async_inference_example.py \
    --checkpoint checkpoints/qwen_vla_async_best.pt \
    --duration 10.0 \
    --vlm-hz 3.33 \
    --action-hz 10.0
```

**ì‹¤ì œ ë¹„ë™ê¸° ë™ì‘:**
```python
inference = AsyncVLAInference(
    model=model,
    vlm_update_hz=3.33,
    action_expert_hz=10.0,
)

# ğŸ”¥ VLMì„ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ì‹œì‘ (non-blocking, ~311ms)
if inference.should_start_vlm_update(current_time):
    inference.start_vlm_update(instruction, image_paths)
    # ë©”ì¸ ë£¨í”„ëŠ” ì¦‰ì‹œ ë‹¤ìŒìœ¼ë¡œ ì§„í–‰

# ğŸ”¥ Action ì˜ˆì¸¡ì€ ë©”ì¸ ë£¨í”„ì—ì„œ ê³„ì† ì‹¤í–‰ (10 Hz)
action = inference.predict_action(sensor_window)  # ~20-30ms
```

**íƒ€ì„ë¼ì¸ ì˜ˆì‹œ (ë©€í‹°ë·° 5ê°œ):**
```
t=0ms:       VLM ìŠ¤ë ˆë“œ ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œ, 1484ms ì†Œìš”)
t=0ms:       Action #1 ì˜ˆì¸¡ (ë©”ì¸ ë£¨í”„, VL_feat=None â†’ ëŒ€ê¸°)
t=100ms:     Action #2 ì˜ˆì¸¡ (VLM ì‹¤í–‰ ì¤‘... VL_feat=None â†’ ëŒ€ê¸°)
...
t=1484ms:    VLM ì™„ë£Œ â†’ VL_feat_0 ì—…ë°ì´íŠ¸
t=1500ms:    Action #16 ì˜ˆì¸¡ (VL_feat_0 ì‚¬ìš©)
t=1600ms:    Action #17 ì˜ˆì¸¡ (VL_feat_0 ì¬ì‚¬ìš© #1)
t=1700ms:    ìƒˆ VLM ìŠ¤ë ˆë“œ ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œ)
t=1700ms:    Action #18 ì˜ˆì¸¡ (VL_feat_0 ì¬ì‚¬ìš© #2)
t=1800ms:    Action #19 ì˜ˆì¸¡ (VLM ì‹¤í–‰ ì¤‘... VL_feat_0 ì¬ì‚¬ìš© #3)
...
t=3184ms:    VLM ì™„ë£Œ â†’ VL_feat_1 ì—…ë°ì´íŠ¸
t=3200ms:    Action #33 ì˜ˆì¸¡ (VL_feat_1 ì‚¬ìš©)
...ê³„ì†
```

**í•µì‹¬:**
- VLMì€ ~1484ms ê±¸ë¦¬ì§€ë§Œ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰
- ì²« VLMì´ ì™„ë£Œë  ë•Œê¹Œì§€ ~1.5ì´ˆ ëŒ€ê¸° í•„ìš”
- ì´í›„ Action ExpertëŠ” ë¸”ë¡œí‚¹ ì—†ì´ 10 Hzë¡œ ê³„ì† ë™ì‘
- VL featuresë¥¼ ìµœëŒ€ 1.7ì´ˆê°„ ì¬ì‚¬ìš©í•˜ì§€ë§Œ í•™ìŠµ ì‹œ ì´ë¥¼ ë°˜ì˜í–ˆìœ¼ë¯€ë¡œ ì„±ëŠ¥ ìœ ì§€

---

## ì„±ëŠ¥ ë¹„êµ

| ì§€í‘œ | ê¸°ì¡´ ë™ê¸°ì‹ (ë‹¨ì¼ ì´ë¯¸ì§€) | ê¸°ì¡´ ë™ê¸°ì‹ (ë©€í‹°ë·° 5ê°œ) | ë¹„ë™ê¸° (ê°œì„ ) |
|------|---------------------------|--------------------------|---------------|
| VLM ì‹¤í–‰ ì‹œê°„ | ~311ms | **~1484ms** | 1484ms (ë°±ê·¸ë¼ìš´ë“œ) |
| VLM ì£¼ê¸° | ë§¤ë²ˆ | ë§¤ë²ˆ | **1700msë§ˆë‹¤** |
| Action ìƒì„± ì£¼ê¸° | ~311ms | ~1484ms | **100ms** âœ… |
| Actions/sec | ~3ê°œ | ~0.67ê°œ âŒ | **10ê°œ** âœ… |
| Sensor window | 650 samples | 650 samples | 65 samples |
| ì‹¤ì‹œê°„ ì œì–´ | ë¶ˆê°€ëŠ¥ | **ì™„ì „ ë¶ˆê°€ëŠ¥** âŒ | âœ… **ê°€ëŠ¥** |

---

## ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
Insertion_VLA/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ model_with_sensor.py           # ê¸°ì¡´ ë™ê¸°ì‹ ëª¨ë¸
â”‚   â””â”€â”€ model_with_sensor_async.py     # ìƒˆ ë¹„ë™ê¸° ëª¨ë¸ âœ¨
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ A5st_VLA_TRAIN_VL_Lora_with_sensor.py  # ê¸°ì¡´ í•™ìŠµ
â”‚   â””â”€â”€ A6_VLA_TRAIN_ASYNC.py          # ë¹„ë™ê¸° í•™ìŠµ âœ¨
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ async_inference_example.py     # ë¹„ë™ê¸° ì¶”ë¡  ì˜ˆì œ âœ¨
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ profile_vlm_speed.py           # VLM ì†ë„ í”„ë¡œíŒŒì¼ë§ âœ¨
â””â”€â”€ docs/
    â””â”€â”€ ASYNC_TRAINING.md               # ì´ ë¬¸ì„œ
```

---

## í•™ìŠµ íŒŒì´í”„ë¼ì¸

### Stage 1: Sensor Encoder + Action Expert (VLM frozen)

```bash
# ê¸°ì¡´ê³¼ ë™ì¼, sensor_window_sizeë§Œ ë³€ê²½
torchrun --nproc_per_node=4 training/A5st_VLA_TRAIN_VL_Lora_with_sensor.py \
    --mode train \
    --training-stage stage1 \
    --finetune-vl none \
    --sensor-enabled \
    --sensor-window-size 65 \
    --batch-size 2 \
    --lr 1e-4
```

### Stage 2: LoRA Fine-tuning (ë¹„ë™ê¸° í•™ìŠµ)

```bash
torchrun --nproc_per_node=4 training/A6_VLA_TRAIN_ASYNC.py \
    --finetune-vl lora \
    --stage1-checkpoint checkpoints/qwen_vla_sensor_best.pt \
    --sensor-window-size 65 \
    --vlm-reuse-count 3 \
    --batch-size 2 \
    --lr 1e-4 \
    --vl-lr 1e-5
```

---

## ì£¼ìš” í•˜ì´í¼íŒŒë¼ë¯¸í„°

| íŒŒë¼ë¯¸í„° | ê¸°ë³¸ê°’ | ì„¤ëª… |
|----------|--------|------|
| `sensor_window_size` | 65 | Sensor window í¬ê¸° (100ms @ 650Hz) |
| `vlm_reuse_count` | 17 | VL feature ì¬ì‚¬ìš© íšŸìˆ˜ (ë©€í‹°ë·° 5ê°œ ê¸°ì¤€) |
| `vlm_update_hz` | 0.59 | VLM ì—…ë°ì´íŠ¸ ì£¼íŒŒìˆ˜ (Hz) (ë©€í‹°ë·° 5ê°œ ê¸°ì¤€) |
| `action_expert_hz` | 10.0 | Action Expert ì‹¤í–‰ ì£¼íŒŒìˆ˜ (Hz) |

**âš ï¸ ì£¼ì˜**: ë‹¨ì¼ ì´ë¯¸ì§€ ì‚¬ìš© ì‹œ `vlm_reuse_count=3`, `vlm_update_hz=3.33` ì‚¬ìš© ê°€ëŠ¥

---

## ì‹¤í—˜ ê²°ê³¼

### VLM í”„ë¡œíŒŒì¼ë§ (Qwen2.5-VL-3B)

```
â±ï¸  Latency Statistics:
  Mean:   311.16 ms
  P95:    312.65 ms

ğŸ¯ Achievable Frequencies:
  Mean throughput: 3.21 Hz
  P95 throughput:  3.20 Hz

ğŸ’¡ Recommendations:
  VLM update frequency: 3.33 Hz (300ms)
  VL features reused: 3x
  Sensor window: 65 samples (100ms @ 650Hz)
  Action Expert: 10 Hz
```

### ë¹„ë™ê¸° í•™ìŠµ ë¡œê·¸ ì˜ˆì‹œ

```
[Rank 0] Epoch 1
  ğŸ”„ [Step 0] Extracted new VL features
  âš¡ [Step 10] Action predicted (23.4ms) | vl_reuse: 1/3
  âš¡ [Step 20] Action predicted (22.8ms) | vl_reuse: 2/3
  ğŸ”„ [Step 30] Extracted new VL features | vl_reuse: 0/3
  ...

ğŸ“Š Epoch 1 | Train: 0.00245 | Val: 0.00198
```

---

## FAQ

### Q1: ì™œ sensor windowë¥¼ 650ì—ì„œ 65ë¡œ ì¤„ì˜€ë‚˜ìš”?

A: ê¸°ì¡´ 650 samplesì€ 1ì´ˆì¹˜ ë°ì´í„°ì˜€ìŠµë‹ˆë‹¤. ë¹„ë™ê¸°ì—ì„œëŠ” 100msë§ˆë‹¤ actionì„ ì˜ˆì¸¡í•˜ë¯€ë¡œ, 100msì¹˜ ë°ì´í„°ì¸ 65 samplesë§Œ í•„ìš”í•©ë‹ˆë‹¤.

### Q2: VL featureë¥¼ ì¬ì‚¬ìš©í•´ë„ ì„±ëŠ¥ì´ ê´œì°®ë‚˜ìš”?

A: ë„¤! í•™ìŠµ ì‹œë¶€í„° VL feature ì¬ì‚¬ìš©ì„ ë°˜ì˜í•˜ë¯€ë¡œ, ëª¨ë¸ì´ "ì•½ê°„ ì˜¤ë˜ëœ" ì‹œê° ì •ë³´ë¡œë„ ì •í™•í•œ actionì„ ì˜ˆì¸¡í•˜ë„ë¡ í•™ìŠµë©ë‹ˆë‹¤. ì‹¤ì œ ë¡œë´‡ ì œì–´ì—ì„œë„ ì´ë¯¸ì§€ê°€ í•­ìƒ ìµœì‹ ì¼ ìˆ˜ëŠ” ì—†ìœ¼ë¯€ë¡œ, ì˜¤íˆë ¤ ë” robustí•©ë‹ˆë‹¤.

### Q3: í•™ìŠµ ì‹œì—ëŠ” VL ìºì‹œë¥¼ ì‚¬ìš©í•˜ëŠ”ë°, ì¶”ë¡  ì‹œì—ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?

A: **í•™ìŠµ ì‹œ**ì—ëŠ” VL ìºì‹œë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹ ë¥´ê²Œ í•™ìŠµí•©ë‹ˆë‹¤ (`cache_mode="on"`). **ì¶”ë¡  ì‹œ**ì—ëŠ” ìºì‹œë¥¼ ë„ê³  (`cache_mode="off"`) ì‹¤ì œ VLMì„ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰í•©ë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ í•™ìŠµì€ ë¹ ë¥´ê²Œ, ì¶”ë¡ ì€ ì‹¤ì œ í™˜ê²½ê³¼ ë™ì¼í•˜ê²Œ ë™ì‘í•©ë‹ˆë‹¤.

### Q4: ì‹¤ì œë¡œ 10 Hzë¥¼ ë‹¬ì„±í•  ìˆ˜ ìˆë‚˜ìš”?

A: ë„¤! VLMì„ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰í•˜ë¯€ë¡œ, Action ExpertëŠ” ë©”ì¸ ë£¨í”„ì—ì„œ ë¸”ë¡œí‚¹ ì—†ì´ ~20-30msë§Œì— actionì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤. ì´ë¡ ì ìœ¼ë¡œ ~30-40 Hzë„ ê°€ëŠ¥í•˜ì§€ë§Œ, 10 Hzë¡œ ì„¤ì •í•˜ì—¬ ì•ˆì •ì„±ì„ í™•ë³´í–ˆìŠµë‹ˆë‹¤.

### Q5: ê¸°ì¡´ ì²´í¬í¬ì¸íŠ¸ë¥¼ ë¹„ë™ê¸° ëª¨ë¸ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë‚˜ìš”?

A: ë¶€ë¶„ì ìœ¼ë¡œ ê°€ëŠ¥í•©ë‹ˆë‹¤. Sensor Encoderì™€ Action ExpertëŠ” ê·¸ëŒ€ë¡œ ë¡œë“œ ê°€ëŠ¥í•˜ì§€ë§Œ, sensor window í¬ê¸°ê°€ ë‹¤ë¥´ë¯€ë¡œ Stage 1ë¶€í„° ë‹¤ì‹œ í•™ìŠµí•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.

### Q6: VLMì´ ì‹¤í–‰ë˜ëŠ” ë™ì•ˆ ì˜¤ë˜ëœ VL featuresë¥¼ ì‚¬ìš©í•´ë„ ê´œì°®ë‚˜ìš”?

A: ë„¤! í•™ìŠµ ì‹œ ì´ë¯¸ VL feature ì¬ì‚¬ìš©ì„ ë°˜ì˜í–ˆìœ¼ë¯€ë¡œ, ëª¨ë¸ì€ ìµœëŒ€ **1.7ì´ˆ** ì˜¤ë˜ëœ ì‹œê° ì •ë³´ë¡œë„ ì •í™•í•œ actionì„ ì˜ˆì¸¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì„¼ì„œ ë°ì´í„°ëŠ” ì‹¤ì‹œê°„ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ë¯€ë¡œ, **ì´‰ê° ì •ë³´ëŠ” í•­ìƒ ìµœì‹ **ì…ë‹ˆë‹¤. ì‹¤ì œë¡œ ë‹ˆë“¤ ì‚½ì… ì‘ì—…ì—ì„œëŠ” ì‹œê° ì •ë³´ë³´ë‹¤ ì´‰ê° ì •ë³´ê°€ ë” ì¤‘ìš”í•˜ë¯€ë¡œ ì´ ì „ëµì´ íš¨ê³¼ì ì…ë‹ˆë‹¤.

### Q7: ì¶”ë¡  ì†ë„ë¥¼ ë” ë†’ì¼ ìˆ˜ ìˆë‚˜ìš”?

A: ë„¤! ë‹¤ìŒ ë°©ë²•ë“¤ì„ ì‹œë„í•´ë³´ì„¸ìš”:
- VLM quantization (INT8/INT4) - VLM ì¶”ë¡  ì†ë„ 2-4ë°° í–¥ìƒ
- Flash Attention ì‚¬ìš© (ì´ë¯¸ ì ìš©ë¨)
- Smaller VLM ëª¨ë¸ (Qwen2.5-VL-1.5B) - ë” ë¹ ë¥¸ VLM
- GPU ì—…ê·¸ë ˆì´ë“œ (A100/H100)
- Action Expert ê²½ëŸ‰í™” (hidden_dim ì¶•ì†Œ)

---

## ë‹¤ìŒ ë‹¨ê³„

1. âœ… VLM ì†ë„ í”„ë¡œíŒŒì¼ë§ ì™„ë£Œ
2. âœ… ë¹„ë™ê¸° ëª¨ë¸ êµ¬í˜„ ì™„ë£Œ
3. âœ… ë¹„ë™ê¸° í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ì™„ë£Œ
4. âœ… ë¹„ë™ê¸° ì¶”ë¡  ì˜ˆì œ ì™„ë£Œ
5. â³ Stage 1 í•™ìŠµ ì‹¤í–‰ (sensor_window_size=65)
6. â³ Stage 2 ë¹„ë™ê¸° í•™ìŠµ ì‹¤í–‰
7. â³ ì‹¤ì œ ë¡œë´‡ì—ì„œ ë¹„ë™ê¸° ì¶”ë¡  í…ŒìŠ¤íŠ¸

---

## ì°¸ê³ 

- ê¸°ì¡´ ë¬¸ì„œ: `docs/STAGE2_LORA_TRAINING.md`
- ëª¨ë¸ ê°œì„  ë¬¸ì„œ: `docs/guides/MODEL_IMPROVEMENTS.md`
- VLM í”„ë¡œíŒŒì¼ë§: `vlm_profile_results.json`

---

**ì‘ì„±ì¼**: 2025-10-28
**ì‘ì„±ì**: Claude Code
