# Inference Pipeline Testing Guide

## ê°œìš”

ìµœì í™”ëœ ë¹„ë™ê¸° VLA ëª¨ë¸ì˜ ì™„ì „í•œ ì‹¤ì‹œê°„ ì¶”ë¡  íŒŒì´í”„ë¼ì¸ì„ í…ŒìŠ¤íŠ¸í•˜ëŠ” ê°€ì´ë“œì…ë‹ˆë‹¤.

## ì‹œìŠ¤í…œ êµ¬ì„±

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Data Sources                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Robot PC         â”‚ Jetson (Camera)  â”‚ Sensor PC (C++)          â”‚
â”‚ - Robot_sender   â”‚ - Camera_sender  â”‚ - Sensor_sender          â”‚
â”‚ - 10Hz           â”‚ - 5Hz            â”‚ - 650Hz                  â”‚
â”‚ - ZMQ PUB        â”‚ - ZMQ PUSH       â”‚ - UDP                    â”‚
â”‚ - Port 5556      â”‚ - Port 5555      â”‚ - Port 9999              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                  â”‚                  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚     Inference PC                             â”‚
         â”‚     Async_inference_receiver.py              â”‚
         â”‚                                              â”‚
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
         â”‚  â”‚  VLM Thread (Background, ~2.6Hz)       â”‚ â”‚
         â”‚  â”‚  Time: ~381ms @ 640x360                â”‚ â”‚
         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
         â”‚                                              â”‚
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
         â”‚  â”‚  Action Expert Thread (10Hz)           â”‚ â”‚
         â”‚  â”‚  Time: ~20-30ms per prediction         â”‚ â”‚
         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                   Actions (10Hz)
```

## ì¤€ë¹„ì‚¬í•­

### 1. í•˜ë“œì›¨ì–´

- **Robot PC**: Mecademic ë¡œë´‡ ì œì–´
- **Jetson**: ZED ì¹´ë©”ë¼ 4ëŒ€ + OAK ì¹´ë©”ë¼ 1ëŒ€
- **Sensor PC**: ì„¼ì„œ ë°ì´í„° ìˆ˜ì§‘ (C++)
- **Inference PC**: GPU ì„œë²„ (RTX 4090 ì´ìƒ ê¶Œì¥)

### 2. ë„¤íŠ¸ì›Œí¬ ì„¤ì •

ëª¨ë“  PCê°€ ê°™ì€ ë„¤íŠ¸ì›Œí¬ì— ì—°ê²°ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.

```bash
# IP ì£¼ì†Œ ì˜ˆì‹œ
Robot PC:     10.130.41.110
Jetson:       10.130.41.111
Sensor PC:    10.130.41.112
Inference PC: 10.130.41.113
```

### 3. ì†Œí”„íŠ¸ì›¨ì–´ ì„¤ì¹˜

**ëª¨ë“  PC (Pythonì´ í•„ìš”í•œ ê²½ìš°):**
```bash
pip install zmq numpy
```

**Jetson:**
```bash
pip install pyzmq opencv-python pyzed  # ZED SDK í•„ìš”
```

**Inference PC:**
```bash
pip install torch transformers zmq numpy pillow
```

### 4. ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸

Stage 1 í•™ìŠµ ì™„ë£Œ í›„ ìƒì„±ëœ ì²´í¬í¬ì¸íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤:
```bash
./checkpoints/qwen_vla_sensor_best.pt
```

## í…ŒìŠ¤íŠ¸ ë‹¨ê³„

### Phase 1: ê°œë³„ ì»´í¬ë„ŒíŠ¸ í…ŒìŠ¤íŠ¸

ê° ì»´í¬ë„ŒíŠ¸ë¥¼ ê°œë³„ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•˜ì—¬ ì •ìƒ ì‘ë™ì„ í™•ì¸í•©ë‹ˆë‹¤.

#### 1.1 Robot Sender í…ŒìŠ¤íŠ¸

**Robot PCì—ì„œ ì‹¤í–‰:**

```bash
cd /home/najo/NAS/VLA/Insertion_VLA/Make_dataset

# ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ (ë¡œë´‡ ì—†ì´ í…ŒìŠ¤íŠ¸)
python Optimized_Robot_sender.py --robot off
```

**ì˜ˆìƒ ì¶œë ¥:**
```
================================================================================
ğŸ¤– Optimized Robot Sender
================================================================================
Mode: Simulation Mode
Send Rate: 10 Hz (optimized for Action Expert)
CSV Output: ./dataset/Robot_Data/robot_data_YYYYMMDD_HHMMSS.csv
ZMQ Port: 5556
================================================================================

ğŸ¤– Creating dummy robot for simulation...
âœ… Starting robot data sampling to ./dataset/Robot_Data/... at 10.0 Hz...
âœ… ZMQ Publisher bound to tcp://*:5556 at 10 Hz.
   Topic: 'robot_state', Payload Size: 68 bytes

================================================================================
âœ… Optimized Robot Sender Started
================================================================================
Sampling & Sending at 10 Hz
Press Ctrl+C to stop

ğŸ“Š Robot sampling: 50 samples collected (10.0 Hz avg)
ğŸ“¡ ZMQ sending: 50 messages (10.0 Hz avg, target: 10.0 Hz)
```

**ê²€ì¦ ì‚¬í•­:**
- âœ… Send rateê°€ 10Hzë¥¼ ìœ ì§€í•˜ëŠ”ì§€ í™•ì¸
- âœ… ZMQ ë°”ì¸ë”© ì„±ê³µ í™•ì¸
- âœ… CSV íŒŒì¼ ìƒì„± í™•ì¸

**ì‹¤ì œ ë¡œë´‡ í…ŒìŠ¤íŠ¸:**
```bash
# ë¡œë´‡ ì—°ê²° í›„
python Optimized_Robot_sender.py --robot on
```

#### 1.2 Camera Sender í…ŒìŠ¤íŠ¸

**Jetsonì—ì„œ ì‹¤í–‰:**

```bash
cd /home/najo/NAS/VLA/Insertion_VLA/Make_dataset

# ë¨¼ì € ì¹´ë©”ë¼ ì—°ê²° í™•ì¸
python -c "import pyzed.sl as sl; print('ZED SDK OK')"

# Camera sender ì‹¤í–‰ (Inference PC IP ì„¤ì • í•„ìš”)
python Optimized_Camera_sender.py --server-ip 10.130.41.113
```

**ì˜ˆìƒ ì¶œë ¥:**
```
================================================================================
ğŸ¥ Optimized Camera Sender for Async VLA Inference
================================================================================
Mode: Real-time capture and send
Capture Rate: 5.0 Hz (200ms interval)
Image Size: 1280x720 (will be resized to 640x360 on receiver)
ZMQ Server: 10.130.41.113:5555
Views: 5 (ZED left x4 + OAK x1)
================================================================================

ğŸ” Searching for cameras...
âœ… Found 4 ZED cameras
âœ… Found 1 OAK camera

âœ… ZMQ PUSH socket connected to tcp://10.130.41.113:5555

ğŸ¥ Starting synchronized capture at 5.0 Hz...
Press Ctrl+C to stop

ğŸ“Š Capture stats: 25 frames sent | Avg: 5.0 Hz | Views: 5
```

**ê²€ì¦ ì‚¬í•­:**
- âœ… 5ê°œ ì¹´ë©”ë¼ ëª¨ë‘ ì¸ì‹ í™•ì¸
- âœ… 5Hz ìº¡ì²˜ í™•ì¸
- âœ… ZMQ ì—°ê²° ì„±ê³µ í™•ì¸

#### 1.3 Sensor Sender í…ŒìŠ¤íŠ¸

**Sensor PCì—ì„œ ì‹¤í–‰ (C++ ì½”ë“œ):**

ì‚¬ìš©ìê°€ ì œê³µí•œ C++ ì„¼ì„œ senderë¥¼ ì‹¤í–‰í•˜ì—¬ 650Hz UDP ì „ì†¡ í™•ì¸.

```bash
# ì„¼ì„œ sender ì‹¤í–‰ ì˜ˆì‹œ (ì‚¬ìš©ì ì œê³µ ì½”ë“œ)
./sensor_sender --rate 650 --port 9999 --target 10.130.41.113
```

**ê²€ì¦ ì‚¬í•­:**
- âœ… UDP í¬íŠ¸ 9999 ì „ì†¡ í™•ì¸
- âœ… 650Hz ì „ì†¡ ì†ë„ í™•ì¸

### Phase 2: ìˆ˜ì‹  í…ŒìŠ¤íŠ¸ (Inference PC)

ê° ë°ì´í„° ì†ŒìŠ¤ê°€ ì •ìƒì ìœ¼ë¡œ ìˆ˜ì‹ ë˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.

#### 2.1 Robot ë°ì´í„° ìˆ˜ì‹  í…ŒìŠ¤íŠ¸

**Inference PCì—ì„œ ì‹¤í–‰:**

```bash
cd /home/najo/NAS/VLA/Insertion_VLA/Make_dataset

# ZMQ SUB í…ŒìŠ¤íŠ¸
python -c "
import zmq
import struct
import time

context = zmq.Context()
socket = context.socket(zmq.SUB)
socket.connect('tcp://10.130.41.110:5556')
socket.subscribe(b'robot_state')

print('Waiting for robot data...')
for i in range(10):
    topic, payload = socket.recv_multipart()
    ts, send_ts, force, *joints_pose = struct.unpack('<ddf12f', payload)
    print(f'[{i}] Timestamp: {ts:.3f}, Joints: {joints_pose[:6]}')
    time.sleep(0.1)
print('âœ… Robot data received OK')
"
```

**ì˜ˆìƒ ì¶œë ¥:**
```
Waiting for robot data...
[0] Timestamp: 1730188934.123, Joints: [10.5, 20.7, 30.3, 0.0, 45.0, 0.0]
[1] Timestamp: 1730188934.223, Joints: [10.6, 20.8, 30.4, 0.0, 45.0, 0.0]
...
âœ… Robot data received OK
```

#### 2.2 Camera ë°ì´í„° ìˆ˜ì‹  í…ŒìŠ¤íŠ¸

```bash
python -c "
import zmq
import struct
import time

context = zmq.Context()
socket = context.socket(zmq.PULL)
socket.bind('tcp://*:5555')

print('Waiting for camera data...')
for i in range(5):
    metadata_bytes = socket.recv()
    timestamp, view_count = struct.unpack('<dI', metadata_bytes[:12])
    print(f'[{i}] Timestamp: {timestamp:.3f}, Views: {view_count}')

    for v in range(view_count):
        jpg_data = socket.recv()
        print(f'  View {v+1}: {len(jpg_data)} bytes')

    time.sleep(0.2)
print('âœ… Camera data received OK')
"
```

**ì˜ˆìƒ ì¶œë ¥:**
```
Waiting for camera data...
[0] Timestamp: 1730188934.456, Views: 5
  View 1: 45678 bytes
  View 2: 46123 bytes
  View 3: 45890 bytes
  View 4: 46234 bytes
  View 5: 34567 bytes
...
âœ… Camera data received OK
```

#### 2.3 Sensor ë°ì´í„° ìˆ˜ì‹  í…ŒìŠ¤íŠ¸

```bash
python -c "
import socket
import struct
import time

sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
sock.bind(('0.0.0.0', 9999))
sock.settimeout(2.0)

print('Waiting for sensor data...')
for i in range(50):
    try:
        data, addr = sock.recvfrom(8192)
        print(f'[{i}] Received {len(data)} bytes from {addr}')
    except socket.timeout:
        print('âŒ Timeout - no sensor data received')
        break
else:
    print('âœ… Sensor data received OK')
"
```

### Phase 3: í†µí•© ì¶”ë¡  í…ŒìŠ¤íŠ¸

ëª¨ë“  ë°ì´í„° ì†ŒìŠ¤ê°€ ì •ìƒ ì‘ë™í•˜ë©´, ì™„ì „í•œ ì¶”ë¡  íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.

#### 3.1 ê¸°ë³¸ ì¶”ë¡  ì‹¤í–‰

**Inference PCì—ì„œ ì‹¤í–‰:**

```bash
cd /home/najo/NAS/VLA/Insertion_VLA/Make_dataset

python Async_inference_receiver.py \
    --checkpoint ../checkpoints/qwen_vla_sensor_best.pt \
    --robot-ip 10.130.41.110 \
    --robot-port 5556 \
    --camera-port 5555 \
    --sensor-port 9999 \
    --vl-reuse 4
```

**ì˜ˆìƒ ì¶œë ¥:**
```
================================================================================
Initializing Async VLA Inference Engine
================================================================================
Device: cuda
Model: Qwen/Qwen2.5-VL-3B-Instruct
Image Resize: 640x360
Sensor Window: 65 samples (100ms @ 650Hz)
Action Expert: 10.0 Hz
VL Reuse: 4x
Fusion Strategy: concat
Loading checkpoint: ../checkpoints/qwen_vla_sensor_best.pt
âœ… Checkpoint loaded successfully
================================================================================

âœ… Camera PULL listening on port 5555
âœ… Robot SUB connected to 10.130.41.110:5556
âœ… Sensor UDP Receiver started on port 9999

â³ Calibrating sensor clock offset (first 50 batches)...
âœ… Sensor Clock Offset Calibrated: 12.3 ms

================================================================================
Async Real-time Inference Started
================================================================================
Action Expert: 10.0 Hz (every 100ms)
VL Update: ~2.6 Hz (VL features reused 4x)
Image Resolution: 640x360
Sensor Window: 65 samples (100ms)
Device: cuda
Data Saving: Disabled

Waiting for data from all sources...
Press Ctrl+C to stop

ğŸ”„ [VL Update #1] Completed in 385ms
[ACTION #1] VL_reuse=1/4 | Actions[0]: [0.123, -0.045, 0.089, 0.012, -0.034, 0.067, 0.5] | Time: 24.3ms | Sensor: 65/65
[ACTION #2] VL_reuse=2/4 | Actions[0]: [0.125, -0.043, 0.091, 0.014, -0.032, 0.069, 0.5] | Time: 22.1ms | Sensor: 65/65
[ACTION #3] VL_reuse=3/4 | Actions[0]: [0.127, -0.041, 0.093, 0.016, -0.030, 0.071, 0.5] | Time: 23.5ms | Sensor: 65/65
[ACTION #4] VL_reuse=4/4 | Actions[0]: [0.129, -0.039, 0.095, 0.018, -0.028, 0.073, 0.5] | Time: 21.8ms | Sensor: 65/65
ğŸ”„ [VL Update #2] Completed in 378ms
[ACTION #5] VL_reuse=1/4 | Actions[0]: [0.131, -0.037, 0.097, 0.020, -0.026, 0.075, 0.5] | Time: 24.1ms | Sensor: 65/65
...

--- Status (14:32:15) ---
VL Updates: 25 | VL avg: 381ms
Actions: 100 | Action avg: 23.2ms
Images recv: View1:500, View2:500, View3:500, View4:500, View5:500
Sensor buffer: 65/65
Robot: J1=45.23Â°, Px=123.45mm
```

#### 3.2 ë°ì´í„° ì €ì¥ ëª¨ë“œ (ë””ë²„ê¹…ìš©)

```bash
python Async_inference_receiver.py \
    --checkpoint ../checkpoints/qwen_vla_sensor_best.pt \
    --robot-ip 10.130.41.110 \
    --robot-port 5556 \
    --camera-port 5555 \
    --sensor-port 9999 \
    --vl-reuse 4 \
    --save-data
```

ì €ì¥ë˜ëŠ” ë°ì´í„°:
- ì´ë¯¸ì§€: `async_inference_YYYYMMDD_HHMMSS/View1-5/*.jpg`
- ë¡œë´‡ ìƒíƒœ: `robot_state_YYYYMMDD_HHMMSS.csv`
- ì„¼ì„œ ë°ì´í„°: `sensor_data_YYYYMMDD_HHMMSS.npz`
- ì¶”ë¡  ê²°ê³¼: `inference_results_YYYYMMDD_HHMMSS.json`

### Phase 4: ì„±ëŠ¥ ê²€ì¦

#### 4.1 íƒ€ì´ë° ê²€ì¦

**ì •ìƒ ë²”ìœ„:**

| í•­ëª© | ëª©í‘œ | ì •ìƒ ë²”ìœ„ | ë¬¸ì œ |
|------|------|-----------|------|
| VL Update | ~381ms | 375-400ms | >500ms |
| Action Expert | ~25ms | 20-30ms | >50ms |
| Action Period | 100ms | 95-105ms | >110ms |
| Sensor Buffer | 65/65 | 60-65 | <30 |

**ë¡œê·¸ í™•ì¸:**
```bash
# VL Update ì‹œê°„ ì¶”ì¶œ
grep "VL Update" inference.log | awk '{print $6}' | sed 's/ms//' > vl_times.txt
python -c "
import numpy as np
times = np.loadtxt('vl_times.txt')
print(f'VL Update: mean={times.mean():.1f}ms, std={times.std():.1f}ms, max={times.max():.1f}ms')
"

# Action Expert ì‹œê°„ ì¶”ì¶œ
grep "ACTION" inference.log | grep "Time:" | awk '{print $9}' | sed 's/ms//' > action_times.txt
python -c "
import numpy as np
times = np.loadtxt('action_times.txt')
print(f'Action Expert: mean={times.mean():.1f}ms, std={times.std():.1f}ms, max={times.max():.1f}ms')
"
```

#### 4.2 ë°ì´í„° íë¦„ ê²€ì¦

```python
import json
import numpy as np

# ì¶”ë¡  ê²°ê³¼ ë¡œë“œ
with open('async_inference_YYYYMMDD_HHMMSS/inference_results_YYYYMMDD_HHMMSS.json') as f:
    results = json.load(f)

# íƒ€ì„ìŠ¤íƒ¬í”„ ë¶„ì„
timestamps = [r['timestamp'] for r in results]
intervals = np.diff(timestamps)

print(f"Total actions: {len(results)}")
print(f"Duration: {timestamps[-1] - timestamps[0]:.1f}s")
print(f"Action rate: {len(results) / (timestamps[-1] - timestamps[0]):.1f} Hz")
print(f"Interval: mean={intervals.mean()*1000:.1f}ms, std={intervals.std()*1000:.1f}ms")

# ì•¡ì…˜ ê°’ ë¶„ì„
actions_first = np.array([r['actions'][0] for r in results])  # First horizon
print(f"\nAction statistics (first horizon):")
print(f"  Mean: {actions_first.mean(axis=0)}")
print(f"  Std:  {actions_first.std(axis=0)}")
print(f"  Min:  {actions_first.min(axis=0)}")
print(f"  Max:  {actions_first.max(axis=0)}")
```

## íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë¬¸ì œ 1: ë°ì´í„° ìˆ˜ì‹  ì•ˆ ë¨

**ì¦ìƒ:**
```
[WAIT] VL Features: False | Images: False (0/5) | Sensor: False (0/65)
```

**ì›ì¸ ë° í•´ê²°:**

1. **ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë¬¸ì œ**
```bash
# ê° PCì—ì„œ ping í…ŒìŠ¤íŠ¸
ping 10.130.41.110  # Robot PC
ping 10.130.41.111  # Jetson
ping 10.130.41.112  # Sensor PC
```

2. **ë°©í™”ë²½ ì°¨ë‹¨**
```bash
# í¬íŠ¸ ì—´ê¸°
sudo ufw allow 5555/tcp
sudo ufw allow 5556/tcp
sudo ufw allow 9999/udp
```

3. **Senderê°€ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ**
```bash
# ê° PCì—ì„œ sender í”„ë¡œì„¸ìŠ¤ í™•ì¸
ps aux | grep sender
```

### ë¬¸ì œ 2: VL Updateê°€ ë„ˆë¬´ ëŠë¦¼

**ì¦ìƒ:**
```
ğŸ”„ [VL Update #10] Completed in 650ms
```

**ì›ì¸ ë° í•´ê²°:**

1. **GPU ë©”ëª¨ë¦¬ ë¶€ì¡±**
```bash
nvidia-smi
# ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
pkill -f "python.*train"
```

2. **ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ ë¯¸ì ìš©**
```python
# Async_inference_receiver.pyì—ì„œ í™•ì¸
# processor.image_processorê°€ 640x360ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸
```

3. **Multi-view ì´ë¯¸ì§€ ìˆ˜ í™•ì¸**
```bash
# 5ê°œ viewê°€ ëª¨ë‘ ìˆ˜ì‹ ë˜ëŠ”ì§€ í™•ì¸
grep "Images recv" inference.log
```

### ë¬¸ì œ 3: Action Expertê°€ ë„ˆë¬´ ëŠë¦¼

**ì¦ìƒ:**
```
[ACTION #10] ... | Time: 89.5ms | ...
```

**ì›ì¸ ë° í•´ê²°:**

1. **ì„¼ì„œ ìœˆë„ìš° í¬ê¸° í™•ì¸**
```python
# 65 samplesë¡œ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
--sensor-window-size 65
```

2. **GPU ê³¼ë¶€í•˜**
```bash
nvidia-smi
# GPU ì‚¬ìš©ë¥ ì´ 95% ì´ìƒì´ë©´ VL reuse count ì¦ê°€
--vl-reuse 6
```

### ë¬¸ì œ 4: ì„¼ì„œ ë²„í¼ê°€ ê³„ì† ë¹„ì–´ìˆìŒ

**ì¦ìƒ:**
```
Sensor buffer: 5/65
```

**ì›ì¸ ë° í•´ê²°:**

1. **UDP ìˆ˜ì‹  í™•ì¸**
```bash
sudo netstat -ulpn | grep 9999
```

2. **Sensor sender í™•ì¸**
```bash
# Sensor PCì—ì„œ í”„ë¡œì„¸ìŠ¤ í™•ì¸
ps aux | grep sensor_sender
```

3. **Clock offset ë¬¸ì œ**
```bash
# Async_inference_receiver.py ë¡œê·¸ì—ì„œ clock offset í™•ì¸
# ì •ìƒ: 10-20ms
# ë¹„ì •ìƒ: >100ms
```

### ë¬¸ì œ 5: ZMQ ì—°ê²° ì‹¤íŒ¨

**ì¦ìƒ:**
```
zmq.error.ZMQError: Address already in use
```

**í•´ê²°:**
```bash
# í¬íŠ¸ë¥¼ ì‚¬ìš©í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ í™•ì¸ ë° ì¢…ë£Œ
lsof -i :5555
kill -9 <PID>

# ë˜ëŠ” ë‹¤ë¥¸ í¬íŠ¸ ì‚¬ìš©
--camera-port 5557
```

## ì„±ëŠ¥ ì²´í¬ë¦¬ìŠ¤íŠ¸

ì‹¤ì œ í…ŒìŠ¤íŠ¸ ì‹œ ë‹¤ìŒ í•­ëª©ì„ í™•ì¸í•˜ì„¸ìš”:

- [ ] **Robot Sender**: 10Hz ìœ ì§€, ZMQ ë°”ì¸ë”© ì„±ê³µ
- [ ] **Camera Sender**: 5Hz ìœ ì§€, 5ê°œ view ëª¨ë‘ ì „ì†¡
- [ ] **Sensor Sender**: 650Hz ìœ ì§€, UDP ì „ì†¡ ì„±ê³µ
- [ ] **Receiver**: ëª¨ë“  ë°ì´í„° ì†ŒìŠ¤ ìˆ˜ì‹  í™•ì¸
- [ ] **VL Update**: 375-400ms ìœ ì§€
- [ ] **Action Expert**: 20-30ms ìœ ì§€
- [ ] **Action Period**: 100ms ê°„ê²© ìœ ì§€
- [ ] **Sensor Buffer**: 60-65/65 ìœ ì§€
- [ ] **ë©”ëª¨ë¦¬ ì‚¬ìš©**: GPU <10GB, CPU <50%
- [ ] **ë°ì´í„° ì €ì¥**: ëª¨ë“  ë°ì´í„° ì •ìƒ ì €ì¥ (--save-data ì‹œ)

## ë‹¤ìŒ ë‹¨ê³„

í…ŒìŠ¤íŠ¸ ì™„ë£Œ í›„:

1. **ì„±ëŠ¥ ë¡œê·¸ ë¶„ì„**: VL/Action ì‹œê°„, ë°ì´í„° íë¦„ í™•ì¸
2. **Action ëª…ë ¹ ê²€ì¦**: ì¶œë ¥ëœ action ê°’ì´ í•©ë¦¬ì ì¸ì§€ í™•ì¸
3. **ì‹¤ì œ ë¡œë´‡ ì ìš©**: Action ëª…ë ¹ì„ ë¡œë´‡ì— ì „ì†¡í•˜ì—¬ ì œì–´ í…ŒìŠ¤íŠ¸
4. **Fine-tuning**: í•„ìš”ì‹œ ëª¨ë¸ ì¬í•™ìŠµ ë˜ëŠ” VL reuse count ì¡°ì •

ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤! ğŸš€
